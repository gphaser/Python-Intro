{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1830db3c-51d7-426b-9dfa-b98a9f4458a1",
   "metadata": {},
   "source": [
    "# Question Data Tutorial\n",
    "The goal of this tutorial is to introduce some useful functions and show how to do typical tasks when working with quantitative educational data. The data included in this tutorial is reflective of what you might see if you are analyzing survey data or exam/test questions.\n",
    "\n",
    "This tutorial assumes you already have basic knowledge of Python and Pandas and have already completed the Exam data tutorial and/or mastered the skills in that lesson. The latter part of this tutorial also assumes you have some basic statistic knowledge (hypothesis testing, p-values, statistical significance).\n",
    "\n",
    "In this lesson, you will learn the following:\n",
    "* How recode variables to new values\n",
    "* Change the names of data frame columns\n",
    "* Concatenate and merge data frames\n",
    "* Wide vs long format for data frames\n",
    "* Contigency tables\n",
    "* Hypothesis testing\n",
    "* Effect size\n",
    "\n",
    "***\n",
    "Created by Dr. Nicholas Young\n",
    "\n",
    "Last modified: April 4, 2025\n",
    "\n",
    "Python version: 3.11.9\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864b748-e48c-453f-b657-1825fc4426da",
   "metadata": {},
   "source": [
    "As will likely be the case for most your files, we start by importing numpy, pandas, and pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45c612-e921-458a-9562-bc53c57db11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4f9c8-2a42-4603-947d-d9187b9ba473",
   "metadata": {},
   "source": [
    "Now let's read in our question files. This time we have two files, one from a morning section of a course and one from an afternoon section of a course. To minimize the amount of typing, I'll use 'm' for morning and 'a' for afternoon in the variables I store my data.\n",
    "\n",
    "Some background on this data:\n",
    "* This instructor's exam had 4 multiple choice questions and 2 free response questions. We only have the multiple choice questions.\n",
    "* 1 is correct while 0 is incorrect\n",
    "* Q1 and Q4 are the same on both exams but the instructor swapped the order of Q2 and Q3 on the two exams. This means that Q2 on the morning exam is Q3 on the afternoon exam and Q3 on the morning exam is Q2 on the afternoon exam.\n",
    "* We also have some data about the students taking the exams. This is stored in the `class_demographics.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c454fb-2fe5-45cc-982d-4a0aaa6dd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = pd.read_csv('morning_exam.csv')\n",
    "a_data = pd.read_csv('afternoon_exam.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbfe288-c650-462e-ad13-97bfba801ecb",
   "metadata": {},
   "source": [
    "Let's start by inspecting our data and see what we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423555b0-90f4-4288-ac09-f500016e1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4edd8-5cd0-4d6c-b91c-2633a6033406",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ad70d-f08f-4126-a5f3-e89fd4fb2303",
   "metadata": {},
   "source": [
    "You'll likely notice a problem in that Q3 is the students' responses rather than whether they are correct or not. Let's address that first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad897a-32df-4966-a1cc-93888ea2a7e0",
   "metadata": {},
   "source": [
    "## Changing the values of variables based on a condition.\n",
    "As is often the case, our data isn't exactly the way we want it. Here, we have a column with student answers rather than whether it is correct not. We want to convert that to correct or not (1/0).\n",
    "\n",
    "Let us assume that \"B\" is the correct answer to Q3 on the afternoon exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d9d9b-c906-4d21-8c8e-8ed828d3a42d",
   "metadata": {},
   "source": [
    "There are two ways to do this. Which one we want to use depends on how many different values there will be after the conversion. For a binary outcome like correct or not, we can use a logic statement. Here, we ask if Q3 is equal to B. If so, assign a 1 and otherwise, assign a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554d9d3-0dfb-4b7b-b0c1-df3b5cea467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data['Q3'] =(a_data['Q3'] == \"B\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc0a1a-7ecc-4da7-b079-93e9b04686c7",
   "metadata": {},
   "source": [
    "Here the `as.type(int)` is important because when we test whether each response in Q3 is B, we get a list of True and False back. True is equivalent to 1 and False is equivalent to 0 so we can convert the logic variable to an integer to get ones and zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d26eb-e1a9-4289-8bf9-f158ddf06f54",
   "metadata": {},
   "source": [
    "If we had multiple values were assigning to (say you were trying to categorize the alternative conception that each response targets), you could use `replace`. In `replace`, you provide a dictionary with the current values followed by the new values. This provides much more flexibility than the previous way. We also aren't restricted to a binary output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01010cf5-c400-4fdc-bfe6-73f05f72d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data['Q3'] = a_data['Q3'].replace({\"A\": 0, \"B\": 1, \"C\": 0, \"D\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8e729-4c04-4f47-8c9f-fa75263ffe10",
   "metadata": {},
   "source": [
    "If we look at the afternoon data now, we will see that all of the questions are now in correct/incorrect format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54040d-f146-49e0-b00f-bd9fd1e30768",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5466bb-4deb-4de3-b178-6157031cafa7",
   "metadata": {},
   "source": [
    "## Examining performance (review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b2c9f-ab3a-4fc0-a200-102b93d5081b",
   "metadata": {},
   "source": [
    "Now that the data are in the correct format, let's see on how the students did. We want to find the fraction of responses that are correct per question as well as the student's score.\n",
    "\n",
    "Try this on your own in the cells below. If you are stuck, expand the header below called solution to see what I found or look back to the Exam data tutorial for useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610bdb2-8994-4de4-bede-a22e85d9ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to put your code for the fraction of correct responses per question\n",
    "# as a hint, 55% of students answered Q2 correctly in the morning class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee64506-8627-4eb8-b5ed-2d50d2414fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to put your code for total score per student\n",
    "# as a hint, student 101 earned a score of 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556517d2-38ec-4bf3-85a7-3ec852621ce9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Examining performance solution\n",
    "Try to do this yourself before looking at the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c28811-00d8-4475-97db-84331b7d7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data[['Q1', 'Q2', 'Q3', 'Q4']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed61dd7-d9ca-4053-a7d0-6a387546d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data[['Q1', 'Q2', 'Q3', 'Q4']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28e5df-c692-4288-b54f-12e446680949",
   "metadata": {},
   "source": [
    "Because the responses are stored as correct or not, the number of correct responses is sum of the column and the number of attempts is the number of rows in the column. This is just the average so I can find the fraction of correct responses by taking the average of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d3877-87d9-4e6c-a1d0-5fbd4171acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data['score'] = m_data['Q1'] + m_data['Q2'] + m_data['Q3'] + m_data['Q4']\n",
    "a_data['score'] = a_data['Q1'] + a_data['Q2'] + a_data['Q3'] + a_data['Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcadd72-f3c1-4bff-8711-233b7312aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23bf16-b043-4a25-8c74-fe34792b3c3c",
   "metadata": {},
   "source": [
    "Again, since each question is graded correct or not, each student's score is the number of questions they get correct, which is the sum of the four question columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f612d0d0-3e08-43b1-ab6a-413a717fe910",
   "metadata": {},
   "source": [
    "## Combining data sets\n",
    "So far, we've treated the two data sets as separate things. However, as the questions are the same, just in a different order, it might be useful to combine the data to get a better sense of how students are doing on these exams. For example, we might need to collect data from multiple classes in order to get a sufficient sample size.\n",
    "\n",
    "Let's introduce some techniques that could be useful for doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4726b-fc70-40ae-a9b3-ac99883d58a2",
   "metadata": {},
   "source": [
    "If I want to combine the data together into a single data frame with 200 rows instead of second data frames with 100 rows, I need each data frame to have the same column names.\n",
    "\n",
    "We've already met this condition so we can use the `concat` function. I include `ignore_index=True` so that a new index will be created. Otherwise, the individual indices of the existing data frames will be kept and you would have two rows with each index (0-99) because `a_data` and `m_data` each have an index of 0-99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70aa7f-2456-4acc-9503-94d0b46e2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([a_data, m_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e3bd5-ad63-44ec-9789-bca0efe698c0",
   "metadata": {},
   "source": [
    "Here's what that looks like without the `ignore_index=True` part. Notice that the first column ends at 99 now instead of 199. Generally it's a good idea to not have the same index twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf79756-c4f4-4097-a39d-c55867330d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([a_data, m_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e72e54-848f-449e-a32b-8b6fe4a3407a",
   "metadata": {},
   "source": [
    "Now that these are combined, it should be easy to do what we did before and take the column means, right? Well, not quite. If we took the column means, this would still work and not throw an error but the means wouldn't mean (pun intended) what we think they do. Because Q2 and Q3 are not the same on each exam, if we took the mean of the columns, we would answer the question of how did students do on the second and third question on each exam rather than how did student do on Q2 and Q3. (Make sure you understand the difference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb980e-f729-4bb3-a214-b33c96b19698",
   "metadata": {},
   "source": [
    "There are a few ways to proceed. One of the easiest ways is to just rename the columns so that the same questions are in columns with the same names. To prevent confusion, I'm going to use \"item\" to refer to the specific question and \"question\" to refer to the order of it on the exam.\n",
    "\n",
    "So for the morning exam, we have\n",
    "* Q1 = I1\n",
    "* Q2 = I2\n",
    "* Q3 = I3\n",
    "* Q4 = I4\n",
    "\n",
    "and for the afternoon exam, we have\n",
    "* Q1 = I1\n",
    "* Q2 = I3\n",
    "* Q3 = I2\n",
    "* Q4 = I4\n",
    "\n",
    "Let's rename the columns using this scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafe492-a030-4dbb-853c-97452864985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data = a_data.rename(columns = {'Q1':'I1', 'Q2':'I2', 'Q3':'I3', 'Q4':'I4'})\n",
    "m_data = m_data.rename(columns = {'Q1':'I1', 'Q3':'I2', 'Q2':'I3', 'Q4':'I4'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb8239-7878-4b06-a0a0-48f53b084417",
   "metadata": {},
   "source": [
    "First, let's see what this did to the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f43a5d-8ad6-4ce9-b8c0-231ad816617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685fcb6-261d-497e-8309-4157bdc9fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601a049-62ef-4657-af28-36d719e3400c",
   "metadata": {},
   "source": [
    "Python is smart enough to match columns if they are in different orders as long as the names are the same. If we `concat` now, we should get what we are hoping for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34535d59-ed23-486e-92b2-26c55bf8c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data = pd.concat([a_data, m_data], ignore_index=True)\n",
    "am_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85180a2-c3c6-4875-8b75-29687116f7da",
   "metadata": {},
   "source": [
    "Now we can get the performance on each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796ada3-a9ed-4591-b0a5-cccd338b2e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data[['I1', 'I2', 'I3', 'I4']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a46380-bd06-4c94-8ae1-52ec40105074",
   "metadata": {},
   "source": [
    "We see that students did best on item 2 and the worst on item 4. They did about the same on items 1 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffe399-b5e7-4590-a148-4b75deac7932",
   "metadata": {},
   "source": [
    "## Switching between long and wide format\n",
    "There are two common formats to store data: the *wide* format and the *long* format. In the wide format, each variable has its own column while in long format, each observation has its own row, with the variable and its value as separate columns. So far, we have only worked in the wide format. Here, we will show how to convert between the two formats.\n",
    "\n",
    "Wide format is probably how you will be working most of the time. However, long format can be useful depending on the task. If you have a lot of blank data (say there are four versions of the exam each with 10 questions and all of the versions are completely different from each other so each student only answers 10 of the 40 possible questions), long format can be a more efficient way to store data. That is, long format can also result in smaller file sizes if the long format equivlent would include a lot of missing data. This can be important if you are working with multi-GB size files or real-world data that is being added to in real-time.\n",
    "\n",
    "Let's show how to convert between these and then an example of where long format can help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d663a1-d649-4d0c-bd64-02ccbc80f66f",
   "metadata": {},
   "source": [
    "To move from wide format to long format, we use the `melt` function. We need specify a few things to switch from wide to long. First, we need to identify the columns we want to remain as columns in the `id_vars` parameter. Next, we need to identify the columns we want to convert to a single column in the `value_vars` parameter. We specify the name of this new column in the `var_name` parameter. The values of the variables we listed in `value_vars` will be stored in a new columm whose name we specify in `value_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a40b6-f450-4f0b-9432-cbcea544e358",
   "metadata": {},
   "source": [
    "For the `am_data`, we want to keep the `id` and `section` variables as columns so we put that into the `id_vars`. We want to collapse the items down into a single column so we put `I1`, `I2`, `I3`, and `I4` into the `value_vars` column. Because these are items, let's call the variable that will store these labels \"item\". Because the values are correct (1) or incorrect (0), let's store the values in a variable called \"correct\". The choice of \"item\" and \"correct\" as names are completely arbitary and you can call them whatever you want. Any variable not specified will in `id_vars` or `value_vars` will be dropped.\n",
    "\n",
    "Let's see what happens when we do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa194c-f197-4ae3-8b8e-54d86a3f49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data2 = pd.melt(am_data, id_vars=['id','section'], value_vars=['I1', 'I2', 'I3', 'I4'],\n",
    "                   var_name='item', value_name='correct')\n",
    "\n",
    "am_data2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0422f-4a97-4e0a-9c0e-a9162228020a",
   "metadata": {},
   "source": [
    "Now there are four columns instead of 6. All the data are still there, just in a different format. We can confirm this by checking the shape of the data frames. We have 200 students answering four questions each. We should then have 200 x 4 = 800 rows in the long format, which we do. In this case, we didn't shrink the data frame number of cells (1200 vs 3200). That is because we didn't have any missing data and kept some columns (\"id\" and \"section\") so these are going to be repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058be42-4348-48ff-97c8-aac7bcea217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(am_data.shape)\n",
    "print(am_data2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ca00e-851c-42cd-9862-a3f2c7af698c",
   "metadata": {},
   "source": [
    "In this long format, we can still to the same type of analyses as before. For example, let's calculate the correctness per question. Here, we can group by the `item` first and then find the average of `correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92309cac-d123-4c0c-a223-07873753be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "am_data2\n",
    "     .groupby('item')['correct']\n",
    "     .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ab79c-87ea-401f-bf4f-bfb390e9df27",
   "metadata": {},
   "source": [
    "This is the same thing we found as before! We can do basically all of the same operations in this format.\n",
    "\n",
    "Let's try to calculate the mean, standard deviation, count, and standard error for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d8dce-3283-4a72-b1ea-40b0ac6567c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data3 =(\n",
    "            am_data2\n",
    "                .groupby('item')\n",
    "                .agg(\n",
    "                    mean=('correct', 'mean'),\n",
    "                    std =('correct', 'std'),\n",
    "                    n= ('correct', 'count')\n",
    "                )\n",
    "                # reset the index so mean, std, and n are column names we can use later\n",
    "                .reset_index()\n",
    "           )\n",
    "am_data3['SE'] = am_data3['std'] / np.sqrt(am_data3['n'])\n",
    "\n",
    "am_data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ab370-b6a4-4970-932d-19e966ea95b8",
   "metadata": {},
   "source": [
    "This is where the format can really shine. Remember how we did the same thing in the Exam data notebook to calcuate these values for 3 exams:\n",
    "\n",
    "```result = (\n",
    "exam_data\n",
    "    .groupby('group').\n",
    "    agg(\n",
    "    exam1_n = ('exam1', 'count'),\n",
    "    exam1_mean=('exam1', 'mean'),\n",
    "    exam1_std= ('exam1', 'std'),\n",
    "    exam2_n = ('exam2', 'count'),\n",
    "    exam2_mean=('exam2', 'mean'),\n",
    "    exam2_std= ('exam2', 'std'),\n",
    "    exam3_n = ('exam3', 'count'),\n",
    "    exam3_mean=('exam3', 'mean'),\n",
    "    exam3_std= ('exam3', 'std'),\n",
    "    )\n",
    ")\n",
    "\n",
    "# calculate the standard error\n",
    "result['exam1_se'] = result['exam1_std'] / np.sqrt(result['exam1_n'])\n",
    "result['exam2_se'] = result['exam2_std'] / np.sqrt(result['exam2_n'])\n",
    "result['exam3_se'] = result['exam3_std'] / np.sqrt(result['exam3_n'])\n",
    "```\n",
    "For that code, for each additional exam, we would have to add an additional four lines of code, one for the mean, standard deviation, count, and standard error.\n",
    "\n",
    "With our data in the long format, our code to calculate these doesn't change regardless of how many questions there are. The only thing we have to change is the variables in `value_vars` in the `pd.melt` command to include more questions.\n",
    "\n",
    "Even then, that isn't technically true. `pd.melt` assumes all columns not in `id_vars` are in `value_vars` so `pd.melt(am_data, id_vars=['id','section'], var_name='item', value_name='correct')` is equivalent to our code (assuming we didn't add other columns like the total score). That means regardless of how many questions we have, the following code will still work and give us the number of responses, the mean, the standard deviation, and standard error of every question. That is, we could calculate these statistics for 100 questions in fewer lines than it took us to calculate these statistics for three exams in the wide format.\n",
    "\n",
    "```\n",
    "am_data2 = pd.melt(am_data, id_vars=['id','section'], var_name='item', value_name='correct')\n",
    "\n",
    "am_data3 =(\n",
    "            am_data2\n",
    "                .groupby('item')\n",
    "                .agg(\n",
    "                    mean=('correct', 'mean'),\n",
    "                    std =('correct', 'std'),\n",
    "                    n= ('correct', 'count')\n",
    "                )\n",
    "                .reset_index()\n",
    "           )\n",
    "am_data3['SE'] = am_data3['std'] / np.sqrt(am_data3['n'])\n",
    "```\n",
    "\n",
    "This is one particularly useful application of switching to long format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc6f852-d6d0-4d6a-ab3c-76cfcde49f5b",
   "metadata": {},
   "source": [
    "Given that the only variables in this long format are item and correct, we can include data from multiple exams, even on completely different topics. To keep track of where the data are coming from, we would probably want another column that records this information (for example, exam number, or course). We could then group by this variable to get the results by different exam, course, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e642858-1df3-46b4-8e9f-cef25a7e89a7",
   "metadata": {},
   "source": [
    "Now, if we want to switch back to to wide format, it's pretty easy to do so. We use `pd.pivot` so convert from long to wide format. We specify the columns to stay the same in the `index` parameter. The column that contains all of the new column names we want is passed to the `columns` parameter and the column that contains all the values is passed to `values`. Notice that `var_name` and `columns` are the same variables and `value_name` and `values` are the same variables for `melt` and `pivot` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096e794-c21d-4e60-a550-61519693d0b8",
   "metadata": {},
   "source": [
    "I include `reset_index()` to add `id` and `section` as columns in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64b44e-c428-4dc8-a7c9-b3821b49a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "am_data2\n",
    "    .pivot(index = ['id', 'section'],columns='item', values='correct')\n",
    "    .reset_index()\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7e00d-f9af-4888-b817-8a55ba993831",
   "metadata": {},
   "source": [
    "Notice this is the same as our original `am_data` data frame before we converted to wide format. I sort here so that the `id` are in the same order as the result above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40863821-a825-4e2e-a487-b0c87ddde53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data.sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a61885-8b9b-4783-ae76-8089a2fcd0dd",
   "metadata": {},
   "source": [
    "### Long vs wide plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47b3b8-881d-4f5b-80a0-dc7168657672",
   "metadata": {},
   "source": [
    "Let's make a plot comparing the performance on the four items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d562e8-6501-4e07-ac30-a86a8c94087f",
   "metadata": {},
   "source": [
    "If we are in the default wide format, here's how we could do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8147d-543b-4e9a-b37e-068e1da974d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: calculate the means\n",
    "mean_correctness = am_data[['I1', 'I2', 'I3', 'I4']].mean()\n",
    "\n",
    "# step 2: create the plot\n",
    "plt.bar(mean_correctness.index, mean_correctness.values, color='grey') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5baf660-fb1d-4de5-b3cd-118aae320922",
   "metadata": {},
   "source": [
    "Now for the long format. I'm using am_data3 because we've already calculated the mean and saved it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696ded6-cff5-4f56-a307-55469fea31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(am_data3['item'], am_data3['mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8c1a3-57a2-4d98-a6b6-dd6533a056b1",
   "metadata": {},
   "source": [
    "Now, this doesn't seem too different. But if we are plotting additional things like including error bars, the long format can be useful because remember, it was easy to calculate the standard error for an arbitrary number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d9606-c82f-4972-acfe-786e63e859de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(am_data3['item'], am_data3['mean'])\n",
    "plt.errorbar(am_data3['item'], am_data3['mean'], yerr=1.96*am_data3['SE'], capsize=5, elinewidth=1, fmt='none', color = 'black')\n",
    "plt.xlabel('Item')\n",
    "plt.ylabel('Correctness')\n",
    "plt.title('Item correctness with 95% confidence interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d5873-39d1-4676-9374-fc41eb1b37ed",
   "metadata": {},
   "source": [
    "## Merging files\n",
    "Sometimes our data is stored in parts and we need to combine data sets to build the entire data set. If the columns are completedly different or not 1-to-1, concatenate probably will not work. Instead, we need a new tool.\n",
    "\n",
    "If you are using data that is stored in a relational database (or data sets built by Dr. Young), you will probably become very familiar with this technique quickly.\n",
    "\n",
    "This tool is `pd.merge`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c4ae8-0464-422a-869f-267ee026e80c",
   "metadata": {},
   "source": [
    "To be concrete, let's import the `class_demographics.csv` file and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af898a-9e6f-4769-ac0c-8c0be8b49c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_csv('class_demographics.csv')\n",
    "\n",
    "demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d245a8-b2f1-4eb3-9c25-ac15a8c95885",
   "metadata": {},
   "source": [
    "You'll notice that this file has a column called `id` which contains three-digit id numbers, the same as the `id` column in our `am_data` data frame. That's because this `id` refers to the same student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a7e0e-e7ec-42ae-9a23-6c078eb828c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data.sort_values('id').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeece23-7ed5-44d6-9288-f392586247d4",
   "metadata": {},
   "source": [
    "That means we can link the two files to add demograhic information for each student to their responses to their exam items.\n",
    "\n",
    "Now, you might be wondering why this information wouldn't already be included in the file. There can be a few different reasons:\n",
    "* The data were collected at different times. Generally instructors don't ask their students demographics on the exam and would have collected this earlier or from some university system. Alternatively, the data might come from two different sources (e.g. consent forms and exams, exams and eLC gradebook, etc.).\n",
    "* Size considerations. If there are three exams and we get the multiple choice questions from each, that would be three files. If we included demographics on each, that would mean we would have two extra copies of the demographic information. For small data sets this isn't an issue but for larger data sets, this could result in very large file sizes that are impractical to work with.\n",
    "* Good data practices. If we are collecting data at multiple time points, it can be useful to separate out the data into the frequency of change. For example, demographics are unlikely to change during the semester so these are essentially fixed. Exam responses change depending on which exam the student is taking so it 'makes sense' to keep these in a separate place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef2f2ea-1199-465b-9bb4-f19d2f9abd07",
   "metadata": {},
   "source": [
    "Let's actually talk about joining the two data set now. There are a few different types of ways to join two data sets. Because the pandas documentation uses SQL terminology, we will do the same. It helps to think about a venn diagram where each circle is a data set.\n",
    "* **Inner join**: this is the intersection of the two data sets. If a student is in both data sets, they will remain in the data after they are inner joined. In a venn diagram, the intersection is when the circles overlap and is the *inner* part of the diagram.\n",
    "* **Outer join**: this is the union of the two data sets. Any record in both data sets will be included, even if there isn't a match in the other. In a venn diagram, the union is both circles shaded and hence is the `outer` part.\n",
    "* **Left join**: this is alternatively known as a left outer join. In this one, we keep all records in the first data set, regardless of whether they have a match and only keep the records in the second data frame if they have a match in the first data set.\n",
    "* **Right join**: this is alternatively known as a right outer join. In this one, we keep all records in the second data set, regardless of whether they have a match and only keep the records in the first data frame if they have a match in the second data set. A right join is equivalent to a left join with the order of the data sets swapped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a9b84-8709-4366-8a4a-ddd0c65afc28",
   "metadata": {},
   "source": [
    "Depending on the problem at hand, you will want to use different joins. Let's do an example to show the difference. To make sure we see different results, let's create a copy of the `demographics` data but remove a few of a rows as well as add a row that doesn't correspond to a student in the question data. We'll call this `demographics_drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89ca2a-acf1-4dfa-9a3e-2223bb58f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_drop = demographics.drop([1, 4, 7])\n",
    "new_row = pd.DataFrame({'id':[500], 'group1':[0], 'group2':[0]})\n",
    "demographics_drop = pd.concat([demographics_drop, new_row],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd3741-ddd0-47cb-b787-98e5b53500c0",
   "metadata": {},
   "source": [
    "As a reminder, let's see how many rows are in the am_data currently and how many students are in this demographics data frame with a few students dropped and added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a848ff-59fd-4927-a72b-e8dd1ce79e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(am_data.shape)\n",
    "print(demographics_drop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e552a3-0336-47d3-8ba3-11b829da6bbd",
   "metadata": {},
   "source": [
    "Remember there are 197 students in the `am_drop` data also in the `demographics_drop` data and 3 that are not. There is also 1 student in the `demographics_drop` data not in the `am_drop` data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61063b5-1dcb-4a57-9b5f-7462b0bba795",
   "metadata": {},
   "source": [
    "First, let's do an inner join, meaning only people in both data frames will remain. We use `pd.merge` or chain to the end of our dataframe with `.merge`. We use the `how` parameter to describe what type of join (inner, out, left, right, or cross, which we ignore for now) and the `on` parameter to set which column we are matching on. The column picked here needs to be in both data sets. If the column names are different, you need to use the `left_on` and `right_on` parameters. Personnally, I recommend using the same name in both data frames to keep things easier to keep track of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb5d56-0c5f-495a-adbc-c7c66b772022",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data.merge(demographics_drop, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d4234-ecf0-468b-9a1a-d440d17d2dd1",
   "metadata": {},
   "source": [
    "Notice that now`group1` and `group2` appear in the `am_data` data frame. You'll also notice that this worked even though the two data frames were not sorted in the same way for their `id` columns. If we have concatenated, the data frames would just be placed next to each other and not matched.\n",
    "\n",
    "We also notice there are 197 rows. This is because 197 of the 200 students were in both data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c8d839-314b-491e-aa27-67c5b4ffb29a",
   "metadata": {},
   "source": [
    "Now let's do an outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff60633-1885-4828-9e4c-a0f3ab5a615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data.merge(demographics_drop, how='outer', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba4045-73ba-4c7c-9a51-09d0550306cd",
   "metadata": {},
   "source": [
    "Now we have 201 rows. This is the 197 students that are in both, the 3 only in `am_data` and the 1 only in `demographics_drop`. Notice that if there isn't a match like for student 500, `NaN` are assigned as the values for that don't have a matching value.\n",
    "\n",
    "**You should always examine your data before and after a merge and check for NaN**. Unexpected NaN can help you determine if you did something incorrectly or your code is not behaving as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a2edcc-70ed-4d4e-bca2-c914fb126eaf",
   "metadata": {},
   "source": [
    "Now let's do a left join. Specifically, we will left join `am_data` with `demographics_drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc021d4-cbad-4bd5-b4d8-4f541b818f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data.merge(demographics_drop, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7990b3a-c8ba-469f-bce2-f847c4e90391",
   "metadata": {},
   "source": [
    "Now we have 200 rows, which is the number of students in the `am_data` because we keep all of those students regardless if they are in the `demographics_drop` data. That means we will have three rows with `NaN` values for `group1` and `group2`. These are students 101, 104, and 107."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41872dba-e40f-4ecf-ad1f-fcb62d8ac314",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data.merge(demographics_drop, how='left', on='id').sort_values('id').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3656c3-5d1e-44fe-8f84-e69c3e98a103",
   "metadata": {},
   "source": [
    "We'll skip right joins because you can swap `am_data` and `demographics_drop` above in the left join code to achieve the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfbb3d-1043-4626-b365-0473227a8985",
   "metadata": {},
   "source": [
    "We can also do the same thing with the long data. This will cause *each* instance of the student to be paired with their demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333bc39e-e403-4287-befe-dcaa94d716f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_data2.merge(demographics_drop, how='left', on='id').sort_values('id').head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecd521-774d-418c-9500-a2867d6a61cf",
   "metadata": {},
   "source": [
    "### Using merged files\n",
    "Let's do some examples of what we can do with this data. We can calculate averages by groups as before.\n",
    "\n",
    "First, let's assign the merged data frame to a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a8e03-582b-4314-a77f-b04b0d7aefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_datam = am_data.merge(demographics_drop, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79549f24-c7b1-476a-b50f-f1f4cd62e602",
   "metadata": {},
   "source": [
    "Now we let's look at the performance on each question split by `group1` and `group2`. Here's how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0937fc-b538-4ced-8b1f-7e546f50454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(am_datam\n",
    "     .groupby(['group1','group2'])[['I1','I2','I3', 'I4']]\n",
    "     .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1d851-c637-4c32-8ac8-e7c45f672317",
   "metadata": {},
   "source": [
    "From this type of analysis, we can see that students with `group1` equal to 1 and `group2` equal to 0 outperform students with `group1` equal to 1 and `group2` equal to 1 on I4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e5a93-c629-4465-a1f4-eca73384a1f2",
   "metadata": {},
   "source": [
    "This type of analysis is especially useful for comparing students with different demographics or other variables of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04fa9a-b7ec-4d0c-ba54-6f9a21d5f69e",
   "metadata": {},
   "source": [
    "## Contigency tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95fbb5-b700-47a1-95c0-4a7c939a626c",
   "metadata": {},
   "source": [
    "Doing something similar, we can also look at performance across questions in relation to each other. For example, if a student got I1 correct, did they also get I2 correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a7759-512d-4186-9070-5a9a015b97d3",
   "metadata": {},
   "source": [
    "Using the same `groupby` technique we have been using, it would look something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39e538-73ed-4a6c-bec1-ecd776635f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_datam.groupby(['I1', 'I2']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ad7d0-e59f-47a2-ac35-8852552c76fc",
   "metadata": {},
   "source": [
    "Here we see if that if a student got I2 correct (the last column), it is basically 50/50 whether they got I1 correct as well (70 correct, 69 incorrect). We also see that 70 students got both questions correct and 34 students got neither question correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f568017d-8928-4e03-82ef-0d926a54688a",
   "metadata": {},
   "source": [
    "This type of table is a called a contingency table or a cross tabulation. In pandas, we can make it easier with the `crosstab` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1e5ab-8550-4bc3-b73d-2e6c2ca5005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(am_datam['I1'], am_datam['I2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747a9e4-2355-4368-b175-153df3a86e39",
   "metadata": {},
   "source": [
    "If we want proportions instead, we can also do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afb4dd-d961-4c20-9831-5536d5efe132",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_contingency_table = pd.crosstab(am_datam['I1'], am_datam['I2'])\n",
    "\n",
    "proportions = my_contingency_table / my_contingency_table.sum().sum() \n",
    "\n",
    "print(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9f1af-7a2a-45cf-bee4-a1d7a8b6358b",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "Now that we can calculate things, let's briefly discuss how to do a statistical test so we can interpret our results.\n",
    "\n",
    "I will assume that all assumptions and requirements of these tests are met to show you how to use the functions but before doing any test, you should look up the assumptions and requirements and perform appropriate checks. For example, does the data need to be independent, normally distributed, have equal variences, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aff9e3-9ffc-4523-a0e6-405a7a6716b5",
   "metadata": {},
   "source": [
    "Suppose that we want to determine whether students with `group1=1` performed better on I1 than students with `group1=0`. We can do that with a t-test.\n",
    "\n",
    "First, let's look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80d232-74bc-4722-be6b-152e2b600343",
   "metadata": {},
   "outputs": [],
   "source": [
    "(am_datam\n",
    "     .groupby(['group1'])[['I1']]\n",
    "     .mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0df6f-729d-418e-8447-bbab1c763821",
   "metadata": {},
   "source": [
    "It clearly looks like there is a difference but it could just be due to chance. That is, if we collected the data next semester, maybe we wouldn't find the same thing. To determine that, we can get a p-value, which gives us a sense of what the chance is that this result could occur by chance if there really wasn't a difference between the two groups.\n",
    "\n",
    "First, we need another package that contains statistical tests. Let's import that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ab737-c914-4a22-9ea8-aca910c74a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8202e-ef3e-474c-8277-b16b913ac73c",
   "metadata": {},
   "source": [
    "We will use `stat.ttest_ind` to perform the test. We use this because our data is not normally distributed (ttest) and because our data is independent (ind) because the two groups contain different people. If the same students were in both groups (say a before and after), we would use a dependent test.\n",
    "\n",
    "To use the test, we need to create dataframes with each group separated out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3de2cb-f6fa-4a96-939f-59446eca42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = am_datam[am_datam['group1'] == 1]['I1']\n",
    "group_0 = am_datam[am_datam['group1'] == 0]['I1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e1bd4-79ae-4b1d-bf64-a4471696e1d1",
   "metadata": {},
   "source": [
    "The `stat.ttest_ind` function returns two values, the t statistic and the p-value. Therefore, to save the results, we need to define two variables. I'll call them t_stat and p_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707899d-bdf0-4e5d-ba5b-948e2dd22a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(group_1, group_0)\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365b495-9d3a-47bd-b3cf-d1f8aa5c3215",
   "metadata": {},
   "source": [
    "How do we interpret this? We can think of the t-statistic like standard errors exception we use a t-distribution rather than a normal distribution. A larger t-value means that the result is less likely to occur by chance. The p-value tells us how likely it is to obtain this t-statistic or a more extreme one by chance. Here, our test tells us we would expect to find a difference of at least 10 percentage points (55.5 vs 45.5) about 20% of the time. As our usual cutoff is $\\alpha=0.05$, we would say that we do not have statistical evidence to claim that the two groups of students are performing differently on this item. So even though there was a 10 percentage point difference, it isn't statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42328b54-a9ae-44fc-bdb4-735828ca64b4",
   "metadata": {},
   "source": [
    "This is just one example of the types of tests we could do (and was technically a difference in means t test). Common ones also include difference of propotions, paired samples, and Chi-squared. For example, if we wanted to see if there is an association between how students answer I1 and I2 (the contigency table), we would use a Chi-Squared test.\n",
    "\n",
    "Assuming we have that contigency table from earlier (`my_contingency_table`), we can do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfe639-090e-48ae-9408-a5e7452c3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_stat, p_value, dof, expected = stats.chi2_contingency(my_contingency_table)\n",
    "\n",
    "print(f\"Chi-squared Statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(f\"Expected Frequencies:\\n{expected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff28a5-fd91-4e65-9058-bf9878b9fca3",
   "metadata": {},
   "source": [
    "I won't go into too much detail about what all of this means (you should do that on your own if you are planning to use Chi-squared tests), but we can interpret the results the same. The p-value is not less than 0.05 so we do not have evidence of an assocation between the two items. This doesn't mean there isn't an association. We just do not have evidence of it in our data. This is the absence of evidence isn't evidence of absence argument. Be careful about reporting your results as people will get these mixed up from time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d90b2-990b-40f5-9bb9-4256aca74e04",
   "metadata": {},
   "source": [
    "## Effect size\n",
    "P-values are often misused and there is a growing trend of moving away from only using p-values to determine whether than effect exists. Another common measure is the effect size. Effect size is essentially a measure of the strength of a relationship. A bigger number is generally better.\n",
    "\n",
    "A common effect size in PER in Cohen's D, which is essentially comparing the difference in two quantites to their combined standard deviation. Any effect can then be reported as the number of standard deviations. This type of analysis is especially useful for comparing learning interventions or pre and post data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668440fb-b349-4e32-97b2-85227f1a8ff9",
   "metadata": {},
   "source": [
    "For this example, let's suppose `group2` represents students who were taught under two different curriculums. We want to know if one curriculum improves learning compared to the other. We measure learning here based on how well perform students on a test with four items. Let's suppose `group2=0` is the standard curriculum and `group2=1` is the updated curriculum.\n",
    "\n",
    "First, let's calculate each student's total score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe545ce3-b7d0-463d-a620-01e1f840f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_datam['total'] = am_datam['I1'] + am_datam['I2'] + am_datam['I3'] + am_datam['I4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f74ca2-3c9b-42c9-906f-6567bb99f1d5",
   "metadata": {},
   "source": [
    "Then let's compute the mean, standard deviation, and count for each group. We've done this multiple times now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fca920-8639-4cbc-949e-dd7c2c3482a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_stats =(\n",
    "    am_datam\n",
    "    .groupby('group2')['total']\n",
    "    .agg(['mean', 'std', 'count'])\n",
    "    .reset_index()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9f858-fe51-49c8-8172-4db0e924f9e8",
   "metadata": {},
   "source": [
    "Now we need to calculate Cohen's d. That is calculated as the difference in means divided by the pooled standard deviation. I won't put that formula as text and have just implemented it below. At a high level, the pooled standard deviation is how to combine the standard deviation of the two groups into one. If the two groups are the same size, then it is just the square root of the average of the two variances. Here, it isn't so simple because the sample sizes are different, and I've implemented the more general formula.\n",
    "\n",
    "I calculate this manually because there isn't a Cohen's D function in scipy stats. There are other packages we could install though that would provide this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bff0a4-9f44-46a2-8a11-9a3a7551739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract means\n",
    "mean1 = group_stats['mean'].iloc[0]\n",
    "mean2 = group_stats['mean'].iloc[1]\n",
    "\n",
    "# calculate Cohen's d \n",
    "cohens_d = (\n",
    "    (mean2 - mean1) /  # Difference in means\n",
    "    np.sqrt(((group_stats['count'].iloc[0] - 1) * group_stats['std'].iloc[0]**2 + \n",
    "              (group_stats['count'].iloc[1] - 1) * group_stats['std'].iloc[1]**2) / \n",
    "             (group_stats['count'].iloc[0] + group_stats['count'].iloc[1] - 2))  # Pooled standard deviation\n",
    ")\n",
    "\n",
    "# report the results\n",
    "print(\"Mean of Group 1:\", mean1)\n",
    "print(\"Mean of Group 2:\", mean2)\n",
    "print(\"Cohen's d:\", cohens_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79ed6b-047e-4c4d-9d81-3d39227a0ebd",
   "metadata": {},
   "source": [
    "What we care about is the d value. It is ~0.05. This means that the new curriculum increased test performance by 0.05 standard deviations. Generally 0.2 is considered small, 0.5 is medium, and 0.8 is large but it is context dependent. Either way, 0.05 is very small and suggests that this new curriculum hardly increased learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad1597-ec57-44b6-bd98-55d386dcb386",
   "metadata": {},
   "source": [
    "***\n",
    "This ends the questions tutorial. You should now have a toolkit that allows you to work with a variety of types of physics education data and perform multiple types of exploratory analyses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
